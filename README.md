RAG Assistant for Alzheimer's Research

Прототип RAG-агента (Retrieval-Augmented Generation) для помощи исследователям в поиске потенциальных мишеней для разработки лекарств от болезни Альцгеймера. Система собирает научные статьи, извлекает и очищает тексты, строит embeddings, индексирует их с помощью FAISS и позволяет задавать вопросы через удобный интерфейс Streamlit.

## Быстрый старт

1. Клонировать репозиторий:
```

git clone <REPO_URL>
cd <REPO_FOLDER>

```

2. Создать виртуальное окружение:
```

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

```

3. Установить зависимости:
```

pip install -r requirements.txt

```

4. Настроить переменные окружения:  
Создайте файл `.env` в корне проекта с ключом:
```

OPENROUTER_API_KEY=<ваш_ключ_OpenRouter>

```

5. Сбор данных:
```

python fetch_articles.py

```
Сырые данные сохраняются в `data/raw/pubmed_biorxiv_raw.csv`.

6. Очистка и подготовка текстов:
```

python preprocess_articles.py

```
Результаты сохраняются в `data/processed/articles_clean.csv` и разделение на чанки в `data/processed/text_chunks.csv`.

7. Создание FAISS индекса и генерация embeddings:
```

python create_embeddings.py

```

8. Запуск интерфейса:
```

streamlit run app.py

```
Введите запрос исследователя, настройте количество retrieved chunks и получите сгенерированный ответ с источниками.

## Структура проекта

```

.
├─ data/
│  ├─ raw/                  # Сырые статьи
│  └─ processed/            # Очистка и чанки
├─ fetch_articles.py         # Сбор статей
├─ preprocess_articles.py    # Очистка текстов
├─ create_embeddings.py      # Embeddings и FAISS индекс
├─ rag_pipeline.py           # Retrieval + Generation
├─ app.py                    # Streamlit интерфейс
├─ requirements.txt
└─ README.md

````

## Модальности данных

Сейчас используется текст статей (abstract, introduction, conclusion).  
Можно расширить на:
- Структурированные данные (базы биомаркеров, мишеней, лекарств, генетические данные, протеомика, метаболомика)
- Изображения и графы (структуры белков, сетевые графы взаимодействий белков/генов)
- Клинические данные (результаты испытаний, patient-level data)

Как это сделать:
- Создать отдельные embeddings для новых модальностей (например, графовые эмбеддинги)
- Объединить с текстовыми через мультимодальный FAISS индекс или Cross-Modal Retrieval
- Расширить RAG pipeline для генерации ответов с учетом всех источников

## Выбор моделей

- SentenceTransformer `all-MiniLM-L6-v2`: малый размер, быстрая генерация embeddings, хорошо работает для научных текстов
- OpenRouter (DeepSeek/Chimera): генерация ответов на основе retrieved chunks, поддержка Markdown-ссылок
- FAISS: эффективный поиск ближайших соседей в векторном пространстве, поддержка больших коллекций документов

## Метрики качества

- Precision@k – доля релевантных retrieved chunks. Почему сейчас 1: все retrieved chunks содержат упоминание "Alzheimer", поэтому все они релевантны.
- Recall@k – простая оценка полноты извлечения. Почему сейчас 1: поскольку мы ограничились выборкой статей только по теме Alzheimer, все ключевые chunks уже присутствуют в retrieved результатах.
- Query term precision@k – доля чанков, содержащих ключевые слова из запроса. Почему сейчас 1: запрос построен с использованием слов, которые встречаются во всех статьях, поэтому каждый retrieved chunk содержит хотя бы одно ключевое слово запроса.

> В будущем, при расширении корпуса статей или добавлении менее релевантных текстов, эти метрики будут принимать значения меньше 1.

## Пример использования

```python
from rag_pipeline import run_rag_pipeline

query = "What are potential targets for Alzheimer's disease treatment?"
result = run_rag_pipeline(query, k=3)

print(result["answer"])
print(result["metrics"])
````

## Вопросы для расширения

* На какие модальности данных можно расширить решение?
* Как это можно сделать?
* Какие модели и почему были выбраны для решения?

## Примечания

* Использование LLM и агентных сред разработки (OpenRouter/DeepSeek) позволяет быстро генерировать ответы на основе retrieved chunks
* Структура проекта позволяет легко добавлять новые источники данных и модальности
* Интерфейс Streamlit обеспечивает быстрый интерактивный доступ к системе для исследователей

```

---

Если хочешь, могу сделать **ещё максимально компактную версию README**, где будут только команды и пути к файлам, без длинных описаний — прямо “для запуска за 1 минуту”.  

Хочешь, чтобы я так сделала?
```
